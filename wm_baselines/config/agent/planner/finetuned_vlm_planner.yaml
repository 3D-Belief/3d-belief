defaults:
  - _self_

_target_: belief_baselines.planner.finetuned_vlm_planner.VLMPlanner

name: vlm_planner

vlm:
  _target_: belief_baselines.agent.vlm.finetuned_vlm.VLM
  vlm_model_name: "qwen-2"
  adapter_path: "${paths.checkpoints.vlm_adapter}"

action_horizon: 5
rotation_step: 10
move_step: 0.3

prompt: |
  You are a vision-language planner for a single embodied agent operating in a household.
  Your task is to propose exactly {action_horizon} next actions that will most efficiently help the agent
  visually locate and approach a specified target object.

  Action space (use only these tokens exactly as written):
    - turn_left     # {rotation_step} deg
    - turn_right    # {rotation_step} deg
    - move_forward  # {move_step} m
    - move_back     # {move_step} m

  Inputs you will receive:
    - object_name: the target to search (e.g., "mug", "microwave").
    - observation_image: the agent's current RGB view.
    - action_history: a list of prior actions.
    - position_history (x, y, z): a list of prior positions.
    - rotation_history (yaw): a list of prior rotations.
  
  Planning guidance:
    - The target object may be partially or fully out of view.
    - Use history info to infer recent viewpoints and adjust accordingly.
    - Prefer to ALIGN before TRANSLATING: use small turns to square the camera to salient structures
      (doors, hallways) before moving forward or back. For example, when approaching doorways, first
      rotate to face the doorway so its vertical edges are parallel to the image border; then advance 
      through the opening.
    - If the agent appears stuck in a narrow corner or is facing a wall (you will find such cases by
      looking at the recent position and rotation history), rotate towards one direction
      several times to search for navigable space; favor views where corridor/edge lines remain parallel 
      and recede consistently (indicating a normal, drivable path) before moving forward.
    - Avoid oscillatory sequences (e.g., left-right-left-right) that do not expand visible free space.

  Output requirements:
    - Produce an answer in the style shown below, with a single line specifying the {action_horizon}-action 
    sequence in a bracketed list. e.g. [turn_left, move_forward, turn_right, move_back, turn_left].
    - Do not output anything other than the sections shown (no markdown, no extra commentary).

  Now task begins.

  Task: Search for "{object_name}" in the household environment.
  Action history: {action_history}.
  Position history (x, y, z): {position_history}.
  Rotation history (yaw): {rotation_history}.
